<!-- html version of Volume 3, Number 3 :  -->
<HTML><HEAD><TITLE>Ray Tracing News, Volume 3, Number 3</TITLE></HEAD>
<BODY>
<CENTER>
<FONT size=+7>Ray Tracing News</FONT>
<P><I>"Light Makes Right"</I>
<P><FONT size=+1>July 13, 1990</FONT>
<P><FONT size=+1>Volume 3, Number 3</FONT>
</CENTER>
<P>
Compiled by <AUTHOR><A HREF="http://www.acm.org/tog/editors/erich/">Eric Haines</A></AUTHOR>
<A HREF="mailto:erich@acm.org">erich@acm.org
</A>.
Opinions expressed are mine.<P>
All contents are copyright (c) 1990, all rights reserved
by the individual authors
<P>
Archive locations:  anonymous FTP at
<A HREF="ftp://ftp-graphics.stanford.edu/pub/Graphics/RTNews/">
ftp://ftp-graphics.stanford.edu/pub/Graphics/RTNews/</A>,<BR>
<A HREF="ftp://wuarchive.wustl.edu/graphics/graphics/ray/RTNews/">
wuarchive.wustl.edu:/graphics/graphics/RTNews</A>, and many others.
<P>
You may also want to check out
<A HREF="index.html">
the Ray Tracing News issue guide</A>
and the
<a href="http://www.cis.ohio-state.edu/hypertext/faq/usenet/graphics/raytrace-faq/top.html">ray tracing FAQ</a>.
<HR>
<P><H2><A NAME="contents">
Contents:
</A></H2>
<UL>
<LI><A HREF="#art1">
Introduction
</A></LI>
<LI><A HREF="#art2">
Ray Tracing Roundtable Announcement
</A></LI>
<LI><A HREF="#art3">
New People, Address Changes, etc
</A></LI>
<LI><A HREF="#art4">
Jarke van Wijk Thesis Availability,
</A></LI>
by Erik Jansen
<LI><A HREF="#art5">
New Name For "Distributed Ray Tracing",
</A></LI>
by Paul Heckbert et al
<LI><A HREF="#art6">
NFF Files from Thierry Leconte
</A></LI>
<LI><A HREF="#art7">
RADIANCE Software Available,
</A></LI>
by Greg Ward
<LI><A HREF="#art8">
Rayshade Updates & SPD Bug,
</A></LI>
by Craig Kolb
<LI><A HREF="#art9">
New Version of Vort Ray Tracer,
</A></LI>
by David Hook
<LI><A HREF="#art10">
Graphics Interface '90,
</A></LI>
by Eric Haines
<LI><A HREF="#art11">
Real3d Review,
</A></LI>
by Haakan "ZAP" Andersson
<LI><A HREF="#art12">
Bits From a Letter by David Jevans
</A></LI>
<LI><A HREF="#art13">
On Antialiasing, & Light and Such,
</A></LI>
by Haakan "ZAP" Andersson
</UL>
========Net News Cullings========
<UL>
<LI><A HREF="#art14">
Summary: Uniform Random Distribution of Points on Sphere's Surface,
</A></LI>
Marshall Cline
<LI><A HREF="#art15">
Ray Tracing & Radiosity,
</A></LI>
by Frank Vance, Mark VandeWettering
<LI><A HREF="#art16">
Ray-Tracing the Torus,
</A></LI>
by Prem Subrahmanyam, Bob Webber
<LI><A HREF="#art17">
Need Help on Superquadrics,
</A></LI>
by Wayne McCormick, Robert Skinner
<LI><A HREF="#art18">
Ray Tracing Penumbral Shadows,
</A></LI>
Prem Subrahmanyam
<LI><A HREF="#art19">
Ray with Bicubic Patch Intersection Problem,
</A></LI>
Wayne Knapp, John Peterson,
Lawrence Kesteloot, Mark VandeWettering, Thomas Williams
<LI><A HREF="#art20">
Rendering Intersecting Glass Spheres,
</A></LI>
by John Cristy, Craig Kolb
<LI><A HREF="#art21">
DKBPC Raytracer,
</A></LI>
by Tom Friedel
<LI><A HREF="#art22">
New release of IRIT solid modeller,
</A></LI>
by Gershon Elber
<LI><A HREF="#art23">
Easier Use of Ray Tracers,
</A></LI>
by Philip Colmer, Mark VandeWettering,
Jack Ritter
<LI><A HREF="#art24">
Raytracer Glass,
</A></LI>
by F. Ken Musgrave, Michael A. Kelly
<LI><A HREF="#art25">
Ray Intersection with Grid,
</A></LI>
by Alasdair Donald Robert McIntyre, Rick Speer
<LI><A HREF="#art26">
Database for DBW-Render,
</A></LI>
by Prem Subrahmanyam
</UL>
<HR>
<H4><FONT size=+1><A NAME="art1">
Introduction
</A></FONT>
</H4>
        Well, I've been absorbed in quality assurance for the updated version
of the radiosity/ray tracing software we've done with HP.  One thing we've
added is texture mapping, and I definitely feel a sense of deja vu, since my
second graphics project at Cornell was to integrate Rikk Carey's texture
mapping software into the modeller and ray tracer.  Here it is six years later
and we're finally using texture mapping in a commercial product.
<P>
        I should mention some resources for all of you who have scanners.
Phil Brodatz's "Textures" book (Dover) is definitely recommended - it's mostly
nicely photographed images of sand, gravel, fur, wood, paper, straw matting,
etc etc, perfect for scanning.  Another Dover book, "The Grammar of Ornament"
by Owen Jones, has many colorful designs from a large variety of cultures.
There are also many other Dover collections of designs which are worth looking
over.
<P>
        A related book that just came out is "Computers, Pattern, Chaos, and
Beauty" by Clifford Pickover (St. Martin's Press).  At first I thought this
was just another fractal book, but there are many other functions and
algorithms explored here.  This book is something like a collection of
"Computer Recreations" columns, and is worth checking out.  One topic mentioned
in the book is creating sea shells by a series of spheres.  This was also
covered in the IEEE CG&A November 1989 article, pages 8-11.  Here's a code
fragment that outputs a series of spheres in NFF (I leave a good view & lights
& colors to you).  Cut the number of steps way down for a rough idea where
the surface is located, and have fun playing with the various numbers and
formulae.
<P>
<PRE>
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;

main(argc,argv)
int argc;  char *argv[];
{
static  double  gamma = 1.0 ;   /* 0.01 to 3 */
static  double  alpha = 1.1 ;   /* &gt; 1 */
static  double  beta = -2.0 ;   /* ~ -2 */
static  int     steps = 600 ;   /* ~number of spheres generated */
static  double  a = 0.15 ;      /* exponent constant */
static  double  k = 1.0 ;       /* relative size */
double  r,x,y,z,rad,angle ;
int     i ;

    for ( i = -steps*2/3; i &lt;= steps/3 ; ++i ) {
        angle = 3.0 * 6.0 * M_PI * (double)i / (double)steps ;
        r = k * exp( a * angle ) ;
        x = r * sin( angle ) ;
        y = r * cos( angle ) ;
        /* alternate formula: z = alpha * angle */
        z = beta * r ;
        rad = r / gamma ;
        printf( "s %g %g %g %g\n", x, y, z, rad ) ;
    }
}
</PRE>
<P>
The interesting thing about the database generated is that it's pretty slow
for most ray tracers (mine included).  There are a lot of spheres in a tiny
cluster at the start of the shell, and the final spheres are large enough that
this tiny cluster is a small part of the environment.  Because the spheres
overlap, each octree node, grid cell, or 5D list is going to be pretty long -
there's a huge amount of depth complexity in this database.  Definitely a
pathological case for most ray tracers, I suspect.
<P>
        Another book which just came out (as in, I just received my copy
minutes ago) is the new Foley & van Dam (& Feiner & Hughes) "Computer
Graphics:  Principles and Practice" from Addison Wesley.  1174 pages, with a
fair number of color plates.  Definitely a good place to start in on any
topic.  A must have; enough said.
<P>
        "Graphics Gems", edited by Andrew Glassner, should also be out soon.
Mine's on order, but hasn't arrived in time to review this issue.  Look for it
- it should be of interest.
<P>
        One more thing.  I recently created a radiosity bibliography which was
posted to USENET.  If you missed it on comp.graphics, it should be available
on <A HREF="ftp://freedom.graphics.cornell.edu">freedom.graphics.cornell.edu</A> (see the RT News header) soon.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art2">
Ray Tracing Roundtable Announcement
</A></FONT>
</H4>
        There will be a "birds of a feather" room for ray tracers to meet and
get to match names to faces at SIGGRAPH.  We'll meet 5:30 to 6:30 pm on
Thursday of SIGGRAPH at some room (see the room listings at registration).
Note that this shouldn't conflict with much, as it's after the sessions and
before the reception.
<P>
        As befits ray tracers, we're aiming for a minimal, parallel approach
for this year's meeting.  There won't be any roundtable, since last year's
meeting had near a hundred people - just going around the room getting names
and interests took half an hour.  So, there is absolutely no agenda for this
meeting; it's simply a place and time to come and meet others in the field.
Hope to see you there.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art3">
New People, Address Changes, etc
</A></FONT>
</H4>
<PRE>
Haakan 'ZAP' Andersson - efficiency, texturing, speed, etc.
EMT AB
Box 40
178 00 Ekeroe
SWEDEN
+(46)16 - 964 60
[no e-mail address for now...]
</PRE>
<P>
   Working with CAD technology, developing add-ons to the popular AutoCAD,
doing RayTracing as a personal midnight oil project, and it might even be
released realsoonow by EMT.  Since my computational powers are limited (PC
style) I enjoy things that make things pretty without bending the clock.  I
love anything that says 3D, but is also interested in other simulations of
real life (AI, sound and speech synthesis etc.).
<P>
P.S.  I showed "RayTracker" ( My Program ) at an exhibition and some people
thought it was darnfast...even though they were using some renderman stuff
earlier...  my suspicion was that my VERY low resolution led them astray
speed-wise, but I do another nice thing:  I trace every 8ighth pixel (Well,
really every 64th (8x8)) first, so you get a quick look of what's happening
very quickly.  Actually, it's a good timer!  When the scan has done the screen
the FIRST time, a 64th of the image is done, i.e.  the amount of seconds
(minutes) this scan takes, this amount of minutes (hours) will the full image
take, approximately.  That's nice.  Well, that IS all for now.
<P>
_______
<P>
Mark A. Cartwright - 3D Modeling, 3D Human Interface, Ray Tracing, Macintosh.
University of Texas
Computation Center
COM 1
Austin, Texas 78712-1110
Phone: (512)-471-3241 ext 306
email: <A HREF="mailto:markc@emx.utexas.edu">markc@emx.utexas.edu</A>
<P>
My background is mostly graphics work - with a little Numeric Control thrown
in for good measure.  Prior to my position here at the University I worked at
Byte By Byte here on the Macintosh version of Sculpt 3D.  Modeling and all
that relates to object creation and editing -- and of course ray tracing are
my main areas of interest.
<P>
________
<P>
<PRE>
Pierre Poulin
Imager
Dept. of Computer Science
University of British Columbia
Vancouver, B.C., Canada
V6T 1W5
</PRE>
<P>
Just in case you might be interested to change it, my new email address is now:
<P>
<PRE>
        <A HREF="mailto:poulin@cs.ubc.ca">poulin@cs.ubc.ca</A>
</PRE>
<P>
I followed my supervisor at the University of British Columbia. The DGP
group at Toronto kindly kept me on their system, but I would prefer being
contacted directly rather than each time through Toronto...
<P>
________
<P>
<PRE>
Drew Whitehouse
E-mail:  <A HREF="mailto:drw900@csc2.anu.edu.au">drw900@csc2.anu.edu.au</A>
Visualization Programmer,               Fax   : (06) 2473425
Australian National University,         Phone : (06) 2495985
Supercomputer Facility.
GPO Box 4, Canberra ACT Australia 2601.
</PRE>
<P>
   I work at the Australian National University Supercomputer Facility as a
visualization programmer.  My interests are scientific visualization, volume
rendering and raytracing.  Currently I'm keeping myself busy inserting bits
and pieces into the MTV raytracer.  The main thing being some sort of volume
rendering, both for voxel data and Perlin style hypertexture (what I've really
got in mind is a tribble teapot.....  )
<P>
________
<P>
<PRE>
Michael A. Kelly
3105 Gateway St. #191
Springfield, Oregon  97477
(503) 726-1859 (home)
(503) 342-2277 (work)
<A HREF="mailto:mkelly@cs.uoregon.edu">mkelly@cs.uoregon.edu</A>
</PRE>
<P>
Interests: accurate duplication of real-world objects, color, efficiency
<P>
<PRE>
Current Project:
I am attempting to write a rendering program for the Macintosh II series.
'Render3D' will be, at least at first, a shareware program.  It is a simple
ray tracer at this point, but by the end of summer it will be considerably
more.  Some of the features I plan to include are:
</PRE>
<P>
<PRE>
        Accurate surface color definitions using spectral energy distributions
                - color calculated on a wavelength-by-wavelength basis
                (now implemented)
        Radiosity method for diffuse reflections
        Phong and Gouraud shading for polygons
        Support for parametrically defined objects
                (including bicubic surface patches)
        Treat light sources as objects
                any normal object can be treated as a light source
        Texture mapping
        Import and Export several file formats, including RenderMan
        Animation
</PRE>
<P>
Of course, I probably won't get to all of these before the end of summer, but
I hope to finish the first four or five of them by the beginning of fall term.
(I am currently an undergraduate computer science major at the University of
Oregon, with one year left to go.)
<P>
________
<P>
<PRE>
# Erik Jansen
# Dept of Industrial Design
# Delft University of Technology
# Jaffalaan 9
# 2628 BX Delft
# The Netherlands
</PRE>
<P>
Erik informs me that the site for a few people has changed:
<P>
<PRE>
alias   wim_bronsvoort  <A HREF="mailto:wim@duticg.tudelft.nl">wim@duticg.tudelft.nl</A>
alias   erik_jansen     <A HREF="mailto:fwj@duticg.tudelft.nl">fwj@duticg.tudelft.nl</A>
alias   frits_post      <A HREF="mailto:frits@duticg.tudelft.nl">frits@duticg.tudelft.nl</A>
</PRE>
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art4">
Jarke van Wijk Thesis Availability,
</A></FONT>
by Erik Jansen (<A HREF="mailto:fwj@duticg.tudelft.nl">fwj@duticg.tudelft.nl</A>)
</H4>
I saw your question about the book of Jarke van Wijk in the [January] issue.
Jack wrote a thesis book which is nicely printed by the Delft University Press.
<P>
The title is:
"On New Types Of Solid Models and Their Visualization with Ray Tracing".
<P>
<PRE>
Subjects that are covered:
- translational, rotational sweep; also in TOG 3(3) 223-237
- sphere sweep, also in EG'84 73-82; and in Computers and Graphics 9(3) 283-290
- blending surfaces; comparable with the work of Middletich and Sears, Sigg'85
- bicubic patches for non-rectangular meshes; also in CAGD 3(1) 1-13
- SML, solid modeling language; also in CAD 18(9).
</PRE>
<P>
There is no discussion in the thesis about efficiency methods (only bounding
boxes).
<P>
The book can be ordered for Dfl. 36.30 (ca. $20 including send costs) by:
Delft University Press
Stevinweg 1
Delft
The Netherlands
fax: +31-15-781661
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art5">
New Name For "Distributed Ray Tracing",
</A></FONT>
by Paul Heckbert et al
</H4>
[If you have more comments, please also send them for publication here. -- EAH]
<P>
A few weeks ago, I asked the following question of the people on
the Ray Tracing News mailing list:
<P>
<PRE>
    From <A HREF="mailto:ph@spline.Berkeley.EDU">ph@spline.Berkeley.EDU</A> Wed Apr 11 18:48:05 1990
</PRE>
<P>
<PRE>
    This is a survey.  Assuming we could rename "Distributed Ray Tracing",
    what should we call it:
</PRE>
<P>
<PRE>
    1) Stochastic Ray Tracing
    2) Probabilistic Ray Tracing
    3) Distributed Ray Tracing (old name ok)
    4) other
</PRE>
<P>
THE RESULTS WERE:
<P>
<PRE>
   14  stochastic ray tracing
    3  monte carlo ray tracing
    2  distributed ray tracing
    1  probabilistic ray tracing
    1  rob cook ray tracing
</PRE>
<P>
"Stochastic Ray Tracing" is the clear favorite of those who responded.
Many commented that they've always found the term "distributed ray tracing"
to be a confusing misnomer.  Brian Corrie put it well:
<P>
<PRE>
    I have a serious problem with the name distributed ray tracing. The
    main reason is the name directly conflicts with the notion of using
    a distributed computer system for ray tracing. Trying to describe
    both of them is a hassle. Because parallel ray tracing is becoming
    quite prominent, this name conflict can be a major pain.
</PRE>
<P>
The plot thickens, however.  Michael Cohen and Joe Cychosz observed
that one could distribute rays regularly throughout a distribution, or
by some other deterministic algorithm, and most people would still call
it "distributed ray tracing".  Wouldn't the proposed new name
"stochastic ray tracing" then be misleading?
<P>
I agree.  That's why I've started using the name "distribution ray
tracing".  To me it captures the central idea that you're modeling the
surface properties as numerical parameters each with a probability
distribution instead of a single, specific value; analogous to the
distinction between a random variable and a standard variable.
There are various numerical integration techniques for simulating this
distribution: uniform sampling or stochastic sampling, non-adaptive or
adaptive, etc, but these are implementation details relative to the
main concept, which is that there's a variable in the shading
formula with a probability distribution that necessitates integration.
Another advantage of the name is that it's similar to the old one.
<P>
Andrew Glassner pointed out that there is another concept in Cook's and
Kajiya's papers that deserves a name, and that concept is that the
stochastic sampling can be done independently in each parameter. Andrew
suggested "simultaneous multidimensional sampling".  Another
possibility that occurs to me is "independent sampling".
<P>
What do y'all think?
<P>
What I'd like to know is: why didn't the reviewers of Cook's
1984 paper scream when he proposed that title?
<P>
<PRE>
Paul Heckbert
<A HREF="mailto:ph@miro.berkeley.edu">ph@miro.berkeley.edu</A>
</PRE>
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art6">
NFF Files from Thierry Leconte
</A></FONT>
</H4>
[I found some wonderful NFF files at the site <A HREF="ftp://irisa.irisa.fr">irisa.irisa.fr</A> [131.254.2.3] in
the NFF directory.  Particularly good is the Amiga computer model, but
all of them are pretty worthwhile.
<P>
<PRE>
BowlingPin.nff - guess
amiga.nff - an Amiga 2000 keyboard and computer (no monitor) - very nice
balls.nff - just a scene generated by SPD ball program
crypt.nff - a mysterious crypt (with columns and whatnot)
expresso.nff [sic] - T. Todd Elvins' Utah espresso maker in NFF format
hangglider.nff - a hang glider
jaws.nff - don't be afraid, it's just a nff scene
matchbox.nff - a box of matches and some matches
room.nff - an office with the desk and others things
spirale.nff - a spiral spline thingie
spring.nff - a spring thing
sps7.nff - a bull sps7 computer box
teapot.nff - the mythical one
temple.nff - pseudo-roman pagan temple something
tpotbis.nff - ye olde teapot, with lid ajar
watch.nff - a wristwatch
x29.nff - fighter plane
</PRE>
<P>
Unfortunately, there are some problems with some databases.  Problems included:
<P>
<PRE>
    - polygonal patches with normals given as [0,0,0].
    - polygons with no area (usually a triangle with a doubled vertex).
    - inconsistently defined polygons.  The NFF format specifies that you
      should output the polygon vertices in a particular order (counter-
      clockwise when viewed from above in a right-handed coordinate
      system).  I suspect you use double sided polygons so that it does not
      matter.
    - other minor problems.
</PRE>
<P>
The files I had problems with:
<P>
<PRE>
amiga.nff - there are a few polygons with no area (doubled vertices).  The
        first is around line 1518 of the file.
jaws.nff - there are tons of polygonal patches with normals of [0,0,0]
room.nff - polygons with [0,0,0] normals, and some no area polygons.  The first
        two polygons in this file are HUGE.  I cannot get the normals per
        vertex to display properly on my system, because some of the vertex
        normals differ inconsistently from the polygon normal (I haven't quite
        figured this out).
spring.nff - the "Shine" and "Transmission" values are switched here, I
        suspect.  Shine is 0, while Kt is 30!  You should definitely fix the
        material setup line here.
temple.nff - no area polygon around line 433.  I can't get the normals to line
        up properly, similar problem to room.nff.
watch.nff - lots of [0,0,0] normals here.
x29.nff - on line 3641 there is an extra vertex - the polygon says it has
        3 vertices, but 4 vertices appear (possibly my file is corrupt).
</PRE>
<P>
Some comments I pasted together from Thierry Leconte
(Thierry.Leconte@irisa.fr), who is the caretaker of the files:
<P>
In fact I'm only a novice in ray-tracing area.  I work on distributed systems
and parallelism.  But ray-tracers are good applications to test such systems.
Now I work on a modified version of VM_pRay (the parallel ray-tracer of
Didier.Badouel@irisa.fr) which run on our own distributed system (called
GOTHIC).  We are writing a motif based window interface for it and I am trying
to collect as many nff files as I can in order to run nice demos on the Gothic
system.  I have made available most of these files and some utilities (among
others yours) via anonymous ftp from irisa.irisa.fr.  Most of the non
classicals scenes I have come from a scene designer Xavier Bouquin who works
on a amiga with the Scult4D program.  and Philippe.Joubert@irisa.fr has
written a sculpttonff converter.  But if someone knows other converters or
interesting nff files I will be happy to add them to my collection!
<P>
VM_pRAY (ray tracer) of Didier Badouel is available at the same site.
<P>
Feel free to use, copy ,modify and distribute these files provided that they
are not use for commercial purpose and that the name of the author is
mentioned.
<P>
Most of these scenes was made on an amiga with Scult4D (a truly great modeler)
then they have been converted to nff file with sc2nff (a PD converter
available on the same site, same directory in the utils.tar archive).
<P>
The author of crypt,jaws,matchbox,room,temple,watch is Xavier Bouquin
(email to <A HREF="mailto:pjoubert@irisa.fr">pjoubert@irisa.fr</A>).
<P>
teapot, x29 were ftp'ed from cs.uoregon.edu.
<P>
amiga, hangglider, teapotbis were PD Scult4D files available on a amiga site
archive (will try in the future to collect any PD Scult4D file an convert them
to nff).
<P>
sps7 was made by hand.
<P>
balls and spirale - generated by program.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art7">
RADIANCE Software Available,
</A></FONT>
by Greg Ward (<A HREF="mailto:greg@hobbes.lbl.gov">greg@hobbes.lbl.gov</A>)
</H4>
For a little over a year now I have been distributing a ray tracing lighting
simulation called RADIANCE through the Sun Academic Software Portfolio.  Since
the software runs on many machines besides the Sun, and not everyone gets the
portfolio as it is, I thought you might be willing to publicize the software
through your rtnews mailing list.
<P>
RADIANCE was written as a lighting simulation more than a renderer, so it does
not allow some of the tricks that are permitted in other ray tracing programs.
(For example, all light sources fall off as 1/r^2.)  It has some of the nicer
features of advanced renderers, such as textures and bump maps (I've always
argued for calling them patterns and textures, respectively), octree spatial
subdivision, several surface primitives and hierarchical instancing.  It's
main distinction, however, is its ability to calculate diffuse interreflection
like a radiosity calculation.  (See the article by Ward, Rubinstein and Clear
in the 1988 Siggraph proceedings.)
<P>
The software is free, and comes with all the C source code, but is not
available through anonymous ftp.  We want to keep track of people who have a
copy of the package so that we can send out update announcements, bug fixes
and so forth.  For this reason we also ask that people do not redistribute the
package without written permission (e-mail is fine).
<P>
Since I am just a mellow Californian who can't handle answering a 24 hour
support hotline, I want to discourage the idly curious, those who just want to
check out another ray tracer, from acquiring this software.  If you are
interested primarily in computer graphics, there are plenty of other ray
tracing programs that do a great job producing attractive imagery.  If, on the
other hand, you are really serious about lighting simulation, this is the
program for you.
<P>
Summary Description of RADIANCE:
<P>
<PRE>
        Lighting calculation and image synthesis using advanced ray tracing.
        Scenes are built from polygons, cones, and spheres made of plastic,
        metal, and glass with optional patterns and textures.
</PRE>
<P>
Detailed Description:
<P>
<PRE>
        RADIANCE was developed as a research tool for predicting the
        distribution of visible radiation in illuminated spaces.  It takes as
        input a three-dimensional geometric model of the physical environment,
        and produces a map of spectral radiance values in a color image.  The
        technique of ray tracing follows light backwards from the image plane
        to the source(s).  Because it can produce realistic images from a
        simple description, RADIANCE has a wide range of applications in
        graphic arts, lighting design, engineering and architecture.
</PRE>
<P>
<PRE>
        The reflectance model accurately predicts both diffuse and specular
        interactions, making it a complete simulation applicable to the design
        of unusual electric and day lighting systems.  Scenes are described by
        boundary representations with polygons, spheres and cones.  Materials
        include plastic, metal, glass, and light.  Textures and patterns can
        be described as functions or data.  Additional programs (generators)
        produce descriptions of compound objects, and allow regular
        transformations and hierarchical scene construction.  A 3D editor is
        being developed.
</PRE>
<P>
<PRE>
        The software package includes some image processing software and
        display programs for X, SunView, and the AED512, and comes with
        converters to Sun rasterfile and Targa formats.  Code is provided for
        writing other drivers, and the list is expected to grow.
</PRE>
<P>
Interface Description:
<P>
<PRE>
        The software is well integrated with the UNIX environment.  Many of
        the programs function as filters, with a reasonable degree of
        modularity.  An interactive program provides quick views of the scene,
        useful for debugging and view determination.  Scenes are described in
        a simple ascii format that is easy to edit and program.  Generators
        are provided for boxes, worms, surfaces of revolution, prisms, and
        functional surfaces (eg.  bicubic patches).  A small library of
        patterns and textures is included.  In general, the software is
        sensible but not mouse-based.
</PRE>
<P>
Overall Goals of Developer:
<P>
<PRE>
        The primary goal of the program is the accurate simulation of light in
        architectural spaces.  Secondary goals are image synthesis and
        geometric modeling.  Efficiency is an important concern in any ray
        tracing method.
</PRE>
<P>
Obtaining RADIANCE:
<P>
<PRE>
        Send a 30+ Mbyte tape cartridge with return envelope and postage to:
</PRE>
<P>
<PRE>
                Greg Ward
                Lawrence Berkeley Laboratory
                1 Cyclotron Rd., 90-3111
                Berkeley, CA  94720
</PRE>
<P>
If you have any questions regarding the applicability of this software to your
needs, feel free to call or (preferably) send e-mail to me directly.
<P>
Sincerely,
<P>
Greg Ward
<P>
<PRE>
Lighting Systems Research Group
<A HREF="mailto:GJWard@Lbl.Gov">GJWard@Lbl.Gov</A>
(415) 486-4757
</PRE>
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art8">
Rayshade Updates & SPD Bug,
</A></FONT>
by Craig Kolb
</H4>
[from various notes to me]
<P>
The Rayshade 3.0 ray tracer is now up to patch level 5.  Rayshade 3.1 is
coming along nicely.  It fixes some of the major problems in rayshade, and
adds a bunch of new features.
<P>
By the way, while playing with the SPD, I ran across a couple of very minor
problems.  In lib.c, you make mention of OUTPUT_POLYGONS, when you really
mean OUTPUT_PATCHES.
<P>
[I have sent Craig release 2.7 of the SPD package, and it's now available for
FTP from <A HREF="ftp://weedeater.math.yale.edu">weedeater.math.yale.edu</A> (130.132.23.17).  It has minor typo fixes
(like the above) and clarifications of the NFF, but no code fixes. - EAH]
<P>
Craig also notes that Przemek Prusinkiewicz's book, "The Algorithmic Beauty
of Plants", will be released at SIGGRAPH this year, complete with lots of
pretty raytraced pictures using Rayshade.  Some of the images generated
were in the March 1990 issue of IEEE CG&A (including the front cover).
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art9">
New Version of Vort Ray Tracer,
</A></FONT>
by David Hook (uunet.UU.NET!munnari!dgh)
</H4>
[the following was pieced together from two notes - EAH]
<P>
<PRE>
I have just installed a new version of the ray tracer in
pub/graphics/vort.tar.Z on munnari.OZ.AU.  It's a bit of an improvement on the
last one, and has some stuff for displaying images as animations on sun's,
PC's, and X11.
</PRE>
<P>
One thing that may be of interest, one of the guys I work with, one Bernie
Kirby, implemented some marble and wood texturing using in the ray tracer.  He
had the following to say:
<P>
<PRE>
        It is an implementation of Ken Perlin's noise function as described in
        "Hypertexture, Computer Graphics, Vol 23, No.3, July 1989, pp
        255-256".  Most of the function names are as given in the paper.
        Also, I think that there may be an error in the paper as the given
        formulae of OMEGA would always produce zero if the actual point falls
        on a lattice point.  (ie. GAMMA(i, j, k) .  (u, v, w) = 0).  Anyway,
        I added in a pseudo random value for the noise at each lattice point
        as well as the gradient values (as described in his '85 paper and it
        seems to work.)
</PRE>
<P>
<PRE>
        The original version (ie.  the one that had zeros at the lattice
        points) produced almost exactly the same effects as displayed in Fig 2
        of J. P. Lewis' paper in SIGRAPH '89 "Algorithms for solid noise
        synthesis".  The changed algorithm still displays some of these
        artifacts (if you really look for them) but no where near as badly as
        in Lewis's paper.
</PRE>
<P>
The only other things of note are that Vort no longer requires
primitives to be axis-aligned and that most things can have tile patterns
mapped on to them (this includes toruses, although flat pixel files
mapped onto a donut can tend to look a little weird). Some people may find
the mapping functions of some use (although having just got a copy of
"Introduction to Ray-Tracing" I notice most of them are in there, the book
shop slugged me $100 bucks for it, sometimes I don't believe this place...)
<P>
<PRE>
Regards,
David.
</PRE>
<P>
PS: we ran your standard rings benchmark at four rays per pixel and it took
two and a half days on a Sun 4 3/90. Is that a record? ( :-) ) Next project
is to speed the mother up...
<P>
________
<P>
[Also, a package called Vogel is also available at munnari - EAH]
<P>
From Tom Friedel, <A HREF="mailto:tpf@jdyx.UUCP">tpf@jdyx.UUCP</A>:
<P>
With Vogel you get 3-d transformation, 3-d and 2-d clipping,
perspective, orthogonal views, some patch functions, and back face removal.
I've wanted to build a bigger package on these routines, some sort of
.nff previewer, but haven't had the time.  Good package because you get
device independence with X11, postscript, others.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art10">
Graphics Interface '90,
</A></FONT>
by Eric Haines
</H4>
        An interesting conference/proceedings which often is overlooked is
"Graphics Interface".  This year's conference, held in Halifax, Nova Scotia,
Canada, had quite a few papers on ray tracing.  I particularly liked Don
Mitchell's "Robust Ray Intersection with Interval Arithmetic" paper.  I'm sure
we'll be seeing interval analysis applied to more areas of graphics in the
years ahead, and this is an interesting application of the technique.
Graphics Interface proceedings can be ordered from:  Morgan Kaufmann
Publishers, (415)-965-4081.  What follows is a list of papers that may be of
interest:
<P>
<PRE>
        Image and Intervisibility Coherence in Rendering
                Joe Marks, Robert Walsh, Jon Christensen and Mark
                Friedell, Harvard U.
</PRE>
<P>
<PRE>
        Robust Ray Intersection with Interval Arithmetic
                Don P. Mitchell, AT&T Bell Laboratories, Murray Hill
</PRE>
<P>
<PRE>
        Approximate Ray Tracing
                David E. Dauenhauer and Sudhanshu K. Semwal, U. Colorado
                at Colorado Springs
</PRE>
<P>
<PRE>
        Octant Priority for Radiosity Image Rendering
                Yigong Wang and Wayne A. Davis, U. Alberta
</PRE>
<P>
<PRE>
        Exploiting Temporal Coherence in Ray Tracing
                J. Chapman, T. W. Calvert and J. Dill, Simon Fraser U.
</PRE>
<P>
<PRE>
        A Ray Tracing Method for Illumination Calculation in
        Diffuse-Specular Scenes
                Peter Shirley, U. Illinois at Urbana-Champaign
</PRE>
<P>
<PRE>
        Voxel Occlusion Testing: A Shadow Determination Accelerator for
        Ray Tracing
                Andrew Woo and John Amanatides, U. Toronto
</PRE>
<P>
<PRE>
        Some Regularization Problems in Ray Tracing
                John Amanatides and Don Mitchell, AT&T Bell Laboratories,
                Murray Hill
</PRE>
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art11">
Real3d Review,
</A></FONT>
Haakan "ZAP" Andersson
</H4>
  I was attending a computer exhibition in Stockholm the other day, and among
all the printers, PC computers and other boring stuff, there were some
bright spots.  In one stand I saw a screen with a checkerboard pattern and a
mirrored sphere on it....  I began to Yawn loudly, but as I was going to leave
a mirrored hand plunged up from the ground and grabbed the sphere, and the
camera made a spin around the whole scene.  It made me interested enough to
enter and look.
<P>
  REAL-3D is apparently a new (so new it's a RealSoonNow product) from the
icy Finland. It's a raytracing program for the Amiga, and it's darn fast
(for being an Amiga, that is). I talked to the program author and he said he
did NOT use the math coprocessor, and it was all in assembler...(Good Grief)
When discussing efficiency he proudly declared that he had NOT looked at others
for algorithms, because he did not want to be influenced, so he had invented it
all from scratch. He had been programming full-time for four years, and from
what I saw, the result was satisfactory, to say the least.
<P>
  A beautiful, OSF/Motif-like user interface and a great interactive object
editor that would make Sculpt-Animate 4d go home and hide under a rug. All
objects were arranged in a hierarchy for animating, and materials and textures
could be assigned to whole hierarchy tree branches. He could even do solid
modelling (I saw a cylinder cut out from another before my very eyes) with
different textures in the 'hole' and the piece the hole was cut out of. It
was also one of the few Amiga tracers to support texture mapping, i.e. you
could map any IFF image onto any surface via some different kinds of projective
mapping (Parallel, Ball, Cylinder)
<P>
  It had a good hybrid between analytic objects (spheres, cylinders, cones and
even hyperbolics (!)) and polygon surfaces. A nice entity was the 'sphere-line'
he used, you simply drew a series of connected lines, and all vertices got
a sphere, and all connecting lines became a cylinder.  [AKA "worms" or "cheese
logs" in other parts of the world - EAH]
<P>
  Animation support looked quite straight forward, and he made a simple
animation of the Real3d logo being flown through before my very eyes (Though
as a wire frame, but I got the hang of animating).
<P>
SPEED:
<P>
  Even though the program ran on an Amiga 2000 (14 Mhz clock) it's speed was
rather fast.  Comparing with my own tracer, running on a 386 machine with full
math coprocessor support, his program looked faster..(!)  The wire frame
representations, used for placing cameras an so forth was real-time, and he
traced a hyperbolic with wood texture with a cylindric hole in about a minute.
He also claimed that finding the colors (for the HAM mode in the Amiga) was
half the work.  He said that an early version used Black&White and it was
almost twice as fast...  (bragging?  :-) Upon being asked how it could be that
fast, he said, "Only me and my brother knows how it works..."  then he smiled.
Heaven knows why...?
<P>
Conclusion:
<P>
REAL3d looks like a speedy hack for the Amiga, and the editor alone makes it a
joy to watch.  I hope this little blond guy from Finland will sell some of
these programs, so he will be able to continue to develop it into something
really nice.
<P>
[Sorry, I don't have an address for where to get it.  Anyone? - EAH]
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art12">
Bits From a Letter by David Jevans
</A></FONT>
</H4>
        ...As for the Arnaldi paper on "mailboxes" (keeping a ray_id for each
object to avoid multiple intersections), I though that was common knowledge!
Cleary's analysis of ray tracing paper (Visual Computer '88), MacDonald's
paper and my paper (Graphics Interface '89) all mention the technique and
reference the paper.  It's a good thing that you put in the RTN if people
really don't know about it!
<P>
        Anyway, my recent work has some pretty important results for the ray
tracing community.  Essentially I show that further work in reducing
ray-object intersections is pretty much pointless (we are close to the fastest
possible time anyway).  I'm just writing a section that illustrates that
hierarchies of 3D voxel grids are superior to bounding volume hierarchies (as
if anyone will believe me!  :-)
<P>
David Jevans @ University of Calgary, Department of Computer Science
               Calgary, Alberta, Canada T2N 1N4
uucp: <A HREF="mailto:jevans@cpsc.ucalgary.ca">jevans@cpsc.ucalgary.ca</A>                  vox: 403-220-7685
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art13">
On Antialiasing, & Light and Such,
</A></FONT>
by Haakan "ZAP" Andersson (no email)
</H4>
(Disclamier: Since I havn't read all theses about anti-aliasing, this might
 be known already, so all I claim to be my ideas may be not, so the stupidity
 is solely on my part :-)
<P>
When raytracing, instead of having one wiz_bang function trace(ray) that
traces through the entire object list (traversing AHBV's as necessary) and
pinning down the poor bastard of an object blocking our way of light and
shining in our face, you might do one little thingy:
<P>
Use TWO functions, ONE that traverses the bounding volumes for a ray, building
an object_list of primitive object this ray (might) intersect, and ONE that
does the real object intersection.  i.e. this:
<P>
<PRE>
        current_list = traverse_abvh(ray);
        pixel = trace_this_list(ray,current_list);
        clear_list(current_list); /* Get rid of it somehow */
</PRE>
<P>
Why da hek do this?  Well, when anti-aliasing, you will virtually hit the same
object(s) inside each pixel, and the 'slack' around the object vs.  bbox will
allow the 'current_list' to contain all objects this ray hits, and any ray
being very close to this very ray, i.e.  all rays within a single pixel.  So,
when anti-aliasing, simply call 'trace_this_list()' with the same list all
over again, only SLIGHTLY different 'ray's.  Ok, there CAN be wrongies some
places, but since you do this for eye-rays, and _I_say_ that for eye-rays you
should use 2d bounding boxes on screen INSTEAD of real bboxes, you simply let
the 2d bboxes be one pixel bigger than they should be, and viola, each pixel
will always yield AT LEAST the object_list containing all objects to be hit in
this pixel and the neighbouring ones.  Got that?
<P>
Any flaws?  Well, since current_list() need to be alloced/malloced in some
way, there might be a speed problem.  Another solution is using a static
object list, and KEEPING the bbox traversal code in 'trace_this_list()' but
ALSO having a 'traverse_abvh()' function, used only upon eye-rays when
anti-aliasing is in effect.  The fact that the list 'trace_this_list()' gets
does NOT contain any bboxes once in a while (i.e.  when we supply a list made
by 'traverse_abvh()' instead of the 'full' object list) is not a problem from
that functions point of view.
<P>
Any flaws NOW?  Well, you might always run out of static storage space.  But
you can always 'realloc()' :-)
<P>
[Comments:  this has a certain sense to it.  By making a "likely candidate
list" for a pixel you can stop wasting time traversing the darn hierarchy.
You could even sort it by the box hit distance, so that when you get do get a
hit from the candidate list you can then simply test this hit against the
remaining candidate distances.  As soon as you reach a candidate distance that
is beyond your hit distance, you stop intersecting.  This candidate list idea
is similar in feel to my Light Buffer lists and Jim Arvo's 5D lists.
<P>
The trick in all this is to make sure your bounding boxes do not fit too
tightly that a pixel makes a difference:  this is easy enough to calculate for
eye rays.  - EAH]
<P>
________
<P>
<CENTER>
                                Light and Such<BR>
                                      or<BR>
<P>
                          "Something's REALLY wrong,<BR>
                           with Bui-Thui Phong"
<P>
        (I think that's the guys name, and since Bui-Thui is his last name,<BR>
         Bui-Thui shading is more appropriate than Phong shading, but...)
<P>
                               By Haakan
</CENTER>
<P>
I have been dissatisfied with Phong's shading model for quite some time, since
it does not accurately enough apply to reality.  There is at least two effects
in 'real life' that i think is important enough to be mad att ol' mr Phong.  I
have called these 'The Rough bug' and 'The nonlinearity bug'
<P>
* The Rough bug
<P>
There is many many ways to see The Rough bug in action in real life, and many
poems have been written about the biggest proof about The Rough bug's, many
lovers have been sitting under it, many songs written about it, and many a
astronomer hase gazed upon it:  The Moon.
<P>
Let's get out late at night, and trying to look straight up.  You will see the
moon, or half of it, or a third, or nothing ("Half moon tonight.  At least
it's better than no moon at all" - Fortune program) But does this moon look
like a Phong shaded sphere?  Were is the ambient, diffuse, and above all,
specular light?  What you (and I) see, is darkness, darkness, more darkness,
and smack, white moon surface, more white moon surface, swack, Darkness,
darkness...  Who stole Kd and Ka?
<P>
The answer lies in the texture of the moon's surface.  It's really a VERY
large amount of small objects, stones, rocks, sand, mountains, e.t.c.  So, any
given spot upon the moon surface, will have normal vectors pointing in every
possible direction, and (using Phong in a small scale) will be shaded (almost)
equally, until, of course, it's in shadow!  This is The Rough Bug, Rough sur-
faces are subject to this effect, and the Phong diffuse component gets more
and more out-of-sync with the actual surface as the surface get's rougher.
<P>
Some questions emerge:
<P>
Q: Is there any way to let a phong-type shading model take this into account,
   without having to model the surface exactly, either in actual geometry or
   as a bump map?
<P>
Another example of this bug you may find outside, at sunset (or almost sunset)
if you stand on a large, flat surface covered with sand, dirt, concrete or
something similar.  Looking towards the setting sun, the surface you are stan-
ding on is darker than when you look away from the sun, by the same reason,
the surface's Roughness.  Small rocks and stuff reflect the sun as you look
away from it (by 'it' i refer to the sun, not the rocks.  You will not see
anything if you look away from the rocks :-) and does not as you look into it
(same 'it').  So much for Specular reflection.  Perhaps some kind of inverted
specular reflection....??
<P>
* The Non Linearity Bug
<P>
Without having ANY physicists backing me up, I dare claim that the (very
linear) equation of the standard Ray Tracing reflection model is goddamnwrong!
I was wearing a ring the other day, sitting in front of a window, looking out
into the sun.  Since my mind is constantly on RayTracing, i saw the reflection
in the window of the sun reflecting in my ring.  I didn't see myself, nor the
ring, not even the room I was in, reflecting in the window glass, only the
(very bright) reflection of the ring (Perhaps the window used adaptive tree
pruning, filtering away all reflections below 0.1?  Nah...don't think so :-)
<P>
Another example was when a friend of mine was standing in front of the very
same window, but it was very very late at night, and the window was black.
But he was backlit by the light from the room, and as I observed his
reflection in the glass, I saw it had somehow higher contrast then my direct
vision of him standing there.  The dark parts of his face (where the shadow of
his nose fell, f'rinstance) was pitch black in the reflection, but the tip of
the very same nose, being lit from behind, appeared very bright in the
reflection.  There were no such differences in luminosity between nose-tip and
nose shadow in the true image of him, not even from the windows viewpoint,
something I verified by crawling up between the window and him, observing him
accurately (with him thinking I was a complete fool -- which I am).
<P>
A question emerges:
<P>
Q: Can this 'non linearity' of reflected images somehow be imported into
   the raytracing algorithm, or is this a local effect in the human eye?
   (Perhaps in MY eyes only... ?)
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<P>
======== USENET cullings follow ===============
<P>
<H4><FONT size=+1><A NAME="art14">
Summary: Uniform Random Distribution of Points on Sphere's Surface,
</A></FONT>
Marshall Cline, (<A HREF="mailto:cline@cheetah.ece.clarkson.edu">cline@cheetah.ece.clarkson.edu</A>)
</H4>
<P>
Organization: ECE Dept, Clarkson Univ, Potsdam, NY
<P>
The original problem was:<BR>
&gt; I need to uniformly(!) spray a sphere's surface with randomly located dots.<BR>
&gt; We can assume the sphere has radius R and is centered at the origin.<BR>
<P>
SOLUTION #1 (by far the most popular):<BR>
&gt; Choose 3 Uniform random values: (rand(-R,R), rand(-R,R), rand(-R,R)).<BR>
&gt; If this is inside the sphere, project that vector onto the sphere's surface.<BR>
    (Sorry I have no references; many many people suggested this)<BR>
<P>
SOLUTION #2:<BR>
&gt; Choose 3 Gaussian randoms: <Normal(0,1), Normal(0,1), Normal(0,1)><BR>
&gt; Project this vector onto the sphere's surface.<BR>
    <A HREF="mailto:bill@stat.washington.edu">bill@stat.washington.edu</A> (Bill Dunlap, Statistics, U. Washington)<BR>
    <A HREF="mailto:jd@shamu.wv.tek.com">jd@shamu.wv.tek.com</A> (JD)<BR>
<P>
(Projecting vector &lt;x,y,z&gt; onto the sphere's surface is done by dividing
each component by sqrt of sum of squares (ie: the vector's length).)
<P>
SOLUTION #3:<BR>
&gt; Pick a random latitude by the inverse sine of a number uniformly<BR>
&gt; distributed over [-1,1].  Pi times another such random number gives<BR>
&gt; you a random longitude, and you're done.<BR>
    <A HREF="mailto:dougm@rice.edu">dougm@rice.edu</A> (Doug Moore)<BR>
<P>
Several other solutions suggested dividing the sphere's surface into small
patches and projecting uniformly into a randomly chosen patch.
<P>
<PRE>
Thanks to all who answered.
Marshall Cline
</PRE>
<P>
PS: I'm implementing this on the Connection Machine.  The SIMD nature of
the CM makes the first soln difficult, since each processor will have to
wait until that last straggler finds a point inside the sphere.  There are
ways around this, like a list of cached 3-space points in each processor,
but there's always a chance that one processor's list will be very short.
Thus I'm going to try the Normal(0,1) solution first.
<P>
PPS: <A HREF="mailto:paul@hpldola.HP.COM">paul@hpldola.HP.COM</A> (Paul Bame) suggested a method (simulated annealing)
which would "evenly distribute" points on the sphere's surface.  Although my
app requires a uniform random distribution, I'm posting this as it may be
appealing (though slow) for someone who wants evenly distributed points.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art15">
Ray Tracing & Radiosity,
</A></FONT>
by Frank Vance (<A HREF="mailto:fvance@airgun.wg.waii.com">fvance@airgun.wg.waii.com</A>)
</H4>
<P>
Organization: Western Geophysical, Houston
<P>
The SIGGRAPH '87 proceedings contain three articles (see biblio. below)
which, taken as a whole, seem to imply that image synthesis will have to
combine both ray tracing and radiosity in order to be able to accurately
render images that contain many "real-world" phenomena.  Two of the papers
point out the difficulty of using ray tracing to render such things as
atmospheric scattering and "participating media".
<P>
I have not seen any further discussion of this view (although I have not yet
seen the SIGGRAPH '89 Proceedings [go easy on me, OK?]), and am wondering what
other researchers, particularly die-hard ray tracers, thought of this.
Can ray tracing correctly render such things without resorting to radiosity
tricks?  Or is the distinction between ray tracing and radiosity
essentially artificial?  What's your opinion?
<P>
<PRE>
Bibliography:
 All below from SIGGRAPH '87 Proceedings a.k.a. Computer Graphics, July 1987,
   v.21 n.4
</PRE>
<P>
<PRE>
        Wallace, John R.; Michael F. Cohen; Donald P. Greenberg
        "A Two-Pass Solution to the Rendering Equation: A Synthesis
         of Ray Tracing and Radiosity Methods", pp 311-320
</PRE>
<P>
<PRE>
        Rushmeier, Holly E.; Kenneth E. Torrance
        "The Zonal Method for Calculating Light Intensities in the
         Presence of a Participating Medium", pp 293-302
</PRE>
<P>
<PRE>
        Nishita, Tomoyuki; Yasuhiro Miyawaki; Eihachiro Nakamae
        "A Shading Model for Atmospheric Scattering Considering
        Luminous Intensity Distribution of Light Sources", pp 303-310
</PRE>
<P>
________
<P>
Re: Ray Tracing & Radiosity, by Mark VandeWettering (<A HREF="mailto:markv@gauss.Princeton.EDU">markv@gauss.Princeton.EDU</A>)
<P>
What I think SHOULD be implied is that normal raytracing techniques are
inadequate to solve a wide variety of lighting situations, particularly those
which deal with solutions to the "ambient" light contribution, diffuse
interreflection, participating media, or color bleeding.
<P>
This doesn't mean that raytracing can't be used to solve problems like this.
As a matter of fact, radiosity can be implemented quite simply using a
raytracer rather than a zbuffer-er for the hemicube calculations.  Raytracing
was a part of Holly Rushmeier's participating media radiosity solution, where
rays were used to perform spatial line integrals of the lighting equation.  If
you examine the 88 and 89 Siggraph proceedings, you will see that many
researchers have shifted to raytracing-like approaches to implement radiosity
solutions.
<P>
&gt;Can ray tracing correctly render such things without resorting to radiosity<BR>
&gt;tricks?  Or is the distinction between ray tracing and radiosity<BR>
&gt;essentially artificial?  What's your opinion?<BR>
<P>
The distinctions aren't artificial, but they are subtle.  For a while,
radiosity meant using matrix equations to solve energy transfer between
Lambertian reflectors.  Later, the n^2 memory requirements were relaxed by
using progressive radiosity, and the algorithm became practical and
competitive with other methods.  Now, integrations of raytracing and radiosity
are beginning to show further improvements in both speed and the kinds of
situations they cover (specular reflection).  And you can be sure that there
will continue to be radiosity papers in THIS years Siggraph too.  (I can
hardly wait!)
<P>
Raytracing is generally conceived to offer solutions to precisely the
situations where early radiosity solutions failed:  environments with highly
specular environments.  It used to be thought that raytracing was too
expensive, but improvements in hardware and in algorithms have made raytracing
tractable and attractive.
<P>
Now, I believe that most algorithms "of the future" will have some sort of a
raytracing core to them, if not for modelling light interactions then probably
just for checking visibility of points.
<P>
How 'bout anyone else?  Any more ideas?
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art16">
Ray-Tracing the Torus,
</A></FONT>
by Prem Subrahmanyam (<A HREF="mailto:prem@geomag.gly.fsu.edu">prem@geomag.gly.fsu.edu</A>)
</H4>
Ok, I've contributed my quadric ray-tracing code.  Now, if someone could tell
me how to do the above, I would greatly appreciate it.  I know it is a 4th
order equation, but I have not even succeeded in locating the equation for the
torus in my math textbooks (except for a spherical coordinate version--and I
don't want to try to convert).  Any help would be appreciated.
<P>
[this has been answered a few times already in the RT News, but I found Bob
Weber's reference of interest.  He also gives a taste of Pat's explanation
-- EAH]
<P>
________
<P>
Reply from Bob Webber (<A HREF="mailto:webber@fender.rutgers.edu">webber@fender.rutgers.edu</A>):<BR>
Organization: Rutgers Univ., New Brunswick, N.J.
<P>
For planar curves we have J.  Dennis Lawrence's A Catalog of Special Plane
Curves (Dover 1972) to satisfy those times when one wakes up in the middle of
the night, racking one's mind trying to remember the equation for the
hippopede.  However, for 3-d, the best I have seen is Pat Hanrahan's A Survey
of Ray-Surface Intersection Algorithms that appears in Andrew Glassner's An
Introduction to Ray Tracing (Academic Press 1989).  There we find, among other
things, the equation for a torus as:
<P>
<PRE>
   (x**2 + y**2 + z**2 - (a**2 + b**2))**2 = 4 a**2 (b**2 - z**2)
</PRE>
<P>
This describes a torus centered at the origin defined by a circle of radius b
being swept along a center defined by a circle of radius a.  It is derived
from considering the intersection of a plane with a torus that yields the two
circles:
<P>
<PRE>
   ((x - a)**2 + z**2 - b**2)((x + a)**2 + z**2 - b**2) = 0
</PRE>
<P>
[if you are unfamiliar with this construction, it is worthwhile pausing here
and savouring how this equation actually works -- sometimes the equations are
prettier than the pictures] and then spinning this intersection by replacing
x**2 with x**2 + y**2 (after some algebraic simplification, which converted
the above to:
<P>
<PRE>
     (x**2 + z**2 - (a**2 + b**2))**2 = 4 a**2 (b**2 - z**2)
</PRE>
<P>
).  The section includes a reference to an unpublished 1982 note by Hanrahan
entitled:  Tori:  algebraic definitions and display algorithms.  The general
scheme for a number of variations on the torus is to start with a quartic
curve of the form f(x**2,y)=0 and then substitute x**2+y**2 for x**2 and z
for y.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art17">
Need Help on Superquadrics,
</A></FONT>
by Wayne McCormick (<A HREF="mailto:wayne@cpsc.ucalgary.ca">wayne@cpsc.ucalgary.ca</A>)
</H4>
        A few months ago I read some articles on superquadrics here on
the net.  It interested me and I decided to try to implement a modeler
based on superquadric shapes.  Since the inside-outside functions are
so easy to use in determining intersections and so forth I thought it would
be somewhat easy to do.  But I stumbled into a small problem.
<P>
Parametrically, a superellipsoid is defined by
<P>
<PRE>
        x = c(u,e1) * c(v,e2)
        y = c(u,e1) * s(v,e2)
        z = s(u,e1)
</PRE>
<P>
        where -pi &lt;= u &lt;= pi, -2pi &lt;= v &lt;= 2pi, and c(u,e1) = cos(u)^e1,
s(u,e1) = sin(u)^e1.  O.K., this is the easy part.  By varying u and v
through the ranges we generate a bunch of points on the surface of the
ellipsoid.  But, the only place that the functions are defined for real
numbers is in the positive octant because once the sin or cos function
becomes negative and e1 and/or e2 are not integers, the function moves out
into the complex plane.
<P>
        Then I tried to calculate everything in the complex plane.  There
are two problems here.  1) speed, 2) how do you map back to image space?
<P>
        Then in Franklin and Barr's paper on "Faster calculation of
superquadric shapes", they say that using an explicit equation and reflecting
47 times is much faster.  Sure I can see that, but the patch that is
generated
by the explicit equation is small and odd shaped, and what 47 directions does
one have to reflect it?
<P>
________
<P>
From Robert Skinner (<A HREF="mailto:robert@texas.esd.sgi.com">robert@texas.esd.sgi.com</A>)<BR>
Organization: Silicon Graphics Inc., Entry Systems Division
<P>
I'm going to suggest this without poring over the references, so I'll
apologize ahead of time:
<P>
Try using the same identities for c(u,e) and s(u,e) as for sin() and
cos():
<P>
<PRE>
        c(-u,e) == c(u,e)
        s(-u,e) == -s(u,e)
        s(pi/2 - u, e) = c(u,e)
        c(pi/2 - u, e) = s(u,e)
</PRE>
<P>
you can make this restriction 0 &lt;= u,v &lt;= pi/2 and solve only the easy
cases.  This also means that you only have to compute 1/4th of u's
range, and 1/8 of v's range, a reduction of 32.  Define
your basic patch over the range above, then define what the other
ranges would be in terms of that:
<P>
<PRE>
e.g.
        0 &lt;= v &lt;= pi/2
        -pi/2 &lt;= u' &lt;= 0                (i.e. u' = -u)
</PRE>
<P>
<PRE>
        then
        x' = c(u',e1) * c(v,e2) = c(u,e1) * c(v,e2) = x
        y' = c(u',e1) * s(v,e2) = c(u,e1) * s(v,e2) = y
        z' = s(u',e1) = -s(u,e1) = -z
</PRE>
<P>
so just reflect your basic patch by -1 in the Z to draw this one.
<P>
Repeat for all other sections of the total range.
This should work, but it looks like you only get 32 sections, not 48.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art18">
Ray Tracing Penumbral Shadows,
</A></FONT>
Prem Subrahmanyam (<A HREF="mailto:prem@geomag.gly.fsu.edu">prem@geomag.gly.fsu.edu</A>)
</H4>
Organization: Florida State University Computing Center
<P>
I would like to hear how people who have done the above have succeeded at
this.  Presently, I am working with DBW_Render which uses the following basic
algorithm.
<P>
Find the direction to the light source and determine distance to this source
(for inverse square shading).  Now, create a random unit vector and scale this
into the direction to light vector using the radius of the light source as the
scaling factor.  Test this new vector for shadows, etc.
<P>
This generates very poor shadows except when the anti-aliasing is turned way
up (6 or greater rays per pixel) since we are either in shadow or not (no
in-betweens).  Does anyone else have any usable suggestions as to how this can
be done where we vary the amount of light depending on how much in shadow it
is (short of firing multiple rays at the light source--pretty much the same as
anti-aliasing).
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art19">
Ray with Bicubic Patch Intersection Problem,
</A></FONT>
Wayne Knapp (<A HREF="mailto:wayneck@tekig5.PEN.TEK.COM">wayneck@tekig5.PEN.TEK.COM</A>)
</H4>
Organization: Tektronix Inc., Beaverton, Or.
<P>
Time for a hard problem.  Anyone have a great idea on how to compute the
a ray intersection with a general bicubic patch?  The methods I've found in
papers so far tend to be very slow.  Seems like most papers take one of two
approaches:
<P>
<PRE>
    1. Sub-divide the patch in many small polygons and ray-trace that.  Works
       but when you have thousands of patches you can end up with millions of
       polygons.
</PRE>
<P>
<PRE>
    2. An Iterative numerical approach, chosing a x,y,z point on the ray and
       checking to see if it intersects the patch by using the x,y,z values
       in the system of equations given by the four cubic equations forming
       the patch.  This of coarse normally requires many trys.
</PRE>
<P>
Does anyone have any better ideas?
<P>
________
<P>
John Peterson (<A HREF="mailto:jp@Apple.COM">jp@Apple.COM</A>)<BR>
Organization: Apple Computer Inc., Cupertino, CA
<P>
I did my MS thesis on comparing techniques #1 and #2.  #1 was definitely the
winner, both in terms of speed and robustness.  #2 requires root finding,
which can have convergence problems (not finding a root, finding the wrong
root, etc).  Also, it performs the surface evaluation (which is expensive) in
the very inner loop of the ray tracing process where it is executed literally
billions of times for a complex image.
<P>
Reducing to polygons first allows the ray tracer to deal strictly with simple,
fast and stable linear math.  It also does the surface evaluation (to generate
the polygons) only once as a pre-process.  Once the polygons are generated,
there are several very effective schemes for reducing the ray-surface search
problem for large quantities of small, simple primitives (e.g., octrees,
bounding volume trees, 5D space, etc).
<P>
For the gory details, see "PRT - A System for High Quality Image Synthesis
of B-Spline Surfaces", MS Thesis, University of Utah, 1988.
<P>
________
<P>
Lawrence Kesteloot, (<A HREF="mailto:lkestel@gmuvax2.UUCP">lkestel@gmuvax2.UUCP</A>)<BR>
Organization: George Mason Univ. Fairfax, Va.
<P>
Check out the book "An Introduction to Splines for use in Computer Graphics &
Geometric Modeling", by Richard H. Bartels, John C. Beatty, and Brian A.
Barsky.  (Morgan Kaufmann Publishers, 1987).  It has a section entitled
Ray-Tracing B-Spline Surfaces (p. 414).  It goes into several steps to speed
up the intersection:
<P>
(I have not read this yet.  I'm summarizing as I read.)
<P>
<PRE>
   1.  Refinement Preprocessing - This breaks the image down into many smaller
         splines.  Each spline covers several 100 pixels.
</PRE>
<P>
<PRE>
   2.  Tree Construction - Break the new (smaller) spline into a bunch of
         boxes, starting with one box for the whole spline, then break that
         down (put all this into a tree).  Intersection with boxes is easy.
         You can find out which of these boxes (check only the leaves of the
         tree) intersects the ray.  This will give you the starting point for
         Newton's iterations.
</PRE>
<P>
<PRE>
   3.  Do newton's iteration to find the exact distance.
</PRE>
<P>
I'm sorry if I've made any errors in the above description.  You're going to
have to get the book, of course, to implement it.  I'm going to implement it
in my own ray-tracing program in the next few weeks, so I'll post the source
if anyone is interested.  It seems like a complicated algorithm, but it may
speed things up quite a bit.  [I never did see the source posted - EAH]
<P>
________
<P>
Mark VandeWettering (<A HREF="mailto:markv@gauss.Princeton.EDU">markv@gauss.Princeton.EDU</A>) writes:
<P>
Well, there is another solution to this problem which people haven't fleshed
out a great deal: generate triangles and raytrace those.
<P>
I hear groans from the audience, but let me put forth the following reasons:
<P>
1.      ray/bicubic patch intersection IS floating point intensive.  The
        best figures I have seen quote around 3K floating point operations
        per ray/patch intersection.  I have a hard time believing you
        couldn't do better with a good hierarchy scheme + good triangle code.
<P>
2.      Even if you can convince me that your bicubic patch intersector
        worked faster than my combination, dicing into triangles is very simple
        and easy to implement.  The same code could also be used to generate
        views of nearly any parametric surface with minimal modification.
<P>
There are (of course) some difficulties.  You would like to subdivide
appropriately, which means being careful about silhouette edges and shadow
edges.  Barr and Von Herzen had an excellent paper in the 1989 siggraph to
illustrate how to implement subdivision.  You might want to check it out.
<P>
(Of course, all this is moot, cuz I never HAVE managed to implement
real ray/patch intersection code)
<P>
________
<P>
Thomas Williams ({ucbvax|sun}!pixar!thaw) replies:<BR>
Organization: Pixar -- Marin County, California
<P>
Another problem which I haven't seen solved is subdivision for
reflections or transmissions which magnify the surface intersection
of this secondary ray.  For example, what is a suitable subdivision
algorithm for surfaces seen through a magnifying glass?  Adaptive techniques
that use gradient differentials can generate gillions of unneeded polygons.
Also the continuity you lose by approximating surfaces with triangles for
curved objects with more than one transmitting surface (like a bottle,
or thick glass) can cause some pretty horrible artifacts.  If it is
important to avoid these problems the only way I know that you can do
it it with ray-surface intersection.
<P>
________
<P>
Mark VandeWettering (<A HREF="mailto:markv@gauss.Princeton.EDU">markv@gauss.Princeton.EDU</A>) then replies:
<P>
The problems you list are legitimate.  However, I would counter with the
following arguments:
<P>
1. How often do scenes which have magnifications through reflection or
refraction REALLY occur.  The answer to this question for me was: never.
Much more difficult is to solve problems with shadow edges, which can
project edges which are irritatingly linear.  Two things will help
soften/alleviate problems which shadow edges:
<P>
<PRE>
        a.      using distributed raytracing to implement penumbras.
                fuzzy boundaries can be more piecewise without causing
                noticeable effects.
        b.      We can help eliminate artifacts by treating light sources
                specially, and subdividing on silhouettes with respect
                to the light source as well as the eye.
</PRE>
<P>
2.  Remember, your screen has on the order of 1M pixels.  Each patch
will probably cover only a vanishingly small fraction of these pixels.
If a patch covers 100 pixels, any subdivision beyond 10x10 is probably
overkill.  Use expected screensize as a heuristic to guide subdivision.
<P>
________
<P>
Thomas Williams ({ucbvax|sun}!pixar!thaw) then replies:
<P>
Don't forget problems with areas of high curvature.  Especially animated
sequences where specular highlights "dance" on sharply curved edges.  A hybrid
approach might work well but, you had better have a _lot_ of memory for all
the polygons you generate.  Thrashing brings the fastest machines to their
knees.  So, I still think there is a place for ray-surface intersections.
<P>
Of course, I guess which approach you take depends on the audience your
playing to.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art20">
Rendering Intersecting Glass Spheres,
</A></FONT>
John Cristy (<A HREF="mailto:cristy@eplrx7.uucp">cristy@eplrx7.uucp</A>)
</H4>
Organization: DuPont Engineering Physics Lab
<P>
I am (still) looking for a renderer (raytracer, radiosity, scanline, etc.)
that can render two intersecting semi-transparent glass spheres and
realistically show the area of intra-penetration.  I have been looking for a
couple months now and have not found a renderer that does this well (or at
all).  Suggestions of public domain or commercial renderers that solve this
problem was welcome.  Please send Email to <A HREF="mailto:cristy@dupont.com">cristy@dupont.com</A>.  Thanks in
advance.
<P>
________
<P>
Craig Kolb (<A HREF="mailto:craig@weedeater.uucp">craig@weedeater.uucp</A>) replies:<BR>
Organization: Yale University Department of Mathematics
<P>
&gt;To accurately model nested objects (for example, if your two<BR>
&gt;spheres had different indices of refraction), you also need to<BR>
&gt;maintain a stack of refraction indices, since you can't assume that<BR>
&gt;when you exit an object, you exit into `air'.<BR>
<P>
Rayshade does exactly this.  But there are still a couple of problems with
rendering intersecting transparent objects.  First, the renderer needs to keep
track of solid body color in order to achieve the proper "filtering" effect
of, say, white light passing through green glass and then blue glass.
<P>
The second and more fundamental problem is how to treat the volume
corresponding to the intersection of the two solids.  Given that solids A and
B each have a set of properties (solid body color, index of refraction, etc.),
what properties should be used in rendering the volume (A ^ B)?
<P>
Doing The Right Thing means resorting to CSG techniques so that one can
specify the properties of (A ^ B) as well as those of A and B.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art21">
DKBPC Raytracer,
</A></FONT>
Tom Friedel (<A HREF="mailto:tpf@jdyx.UUCP">tpf@jdyx.UUCP</A>)
</H4>
Organization: JDyx Enterprises (Atlanta GA)
<P>
The guys on Compuserve seem to have endorsed a (new) ray tracer
called DKBPC, which is available as source.  It appears to
support CSG and Textures from what little I've seen.  Has anyone
evaluated it (i.e., compared it to rayshade, vort, mtv, etc.)  Is it
archived anywhere?
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art22">
New release of IRIT solid modeller,
</A></FONT>
Gershon Elber (<A HREF="mailto:gershon@cs.utah.edu">gershon@cs.utah.edu</A>)
</H4>
Organization: University of Utah CS Dept
<P>
IRIT is a polygonal C.S.G. based solid modeller originally developed on and
for the IBM PC family of computers.  Version 1.x has been released about a
year ago for the IBM PC only.  Since then, it has been ported to unix
environment (SGI Irix 3.2 and BSD4.3) using X11, and all known bugs has been
fixed.
<P>
This is release 2.x of the solid modeller and its accompanying utilities which
include a data viewing program (poly3d), hidden line removal program
(poly3d-h) and simple renderer (poly3d-r).  Thanks to Keith Petersen, all the
sources (Ansi C) for these programs (and executables for the IBM PC) are
available on <A HREF="ftp://simtel20.arpa">simtel20.arpa</A>, directory PD1:MSDOS.IRIT :
<P>
<PRE>
IRIT.ZIP        Full CSG solid modeller, arbitrary orientation
IRITS.ZIP       Turbo C ver 2.0 sources for IRIT
IRITLIBS.ZIP    Libraries for IRIT sources
POLY3D.ZIP      Display 3D polygonal objects, part of IRIT
POLY3DS.ZIP     Turbo C ver 2.0 sources for POLY3D
POLY3D-H.ZIP    Create hidden line removed pict., part of IRIT
POLY3DHS.ZIP    Turbo C ver 2.0 sources for POLY3D-H
POLY3D-R.ZIP    Render poly data into GIF images, part of IRIT
POLY3DRS.ZIP    Turbo C ver 2.0 sources for POLY3D-R
DRAWFN3D.ZIP    Display 3D parametric surfaces, part of IRIT
DRAWFN3S.ZIP    Turbo C ver 2.0 sources for DRAWFN3D
</PRE>
<P>
All above sources are for the unix system as well, but DRAW*.ZIP which has not
been ported (MSDOS only).  In order to unpack ZIP archives in unix environment
you will need to ftp from directory PD3:MISC.UNIX the file UNZIP30.TAR-Z.
<P>
[list of changes deleted - EAH]
<P>
Elber Gershon                            <A HREF="mailto:gershon@cs.utah.edu">gershon@cs.utah.edu</A>
918 University village
Salt Lake City 84108-1180                Tel: (801) 582-1807 (Home)
Utah                                     Tel: (801) 581-7888 (Work)
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art23">
Easier Use of Ray Tracers,
</A></FONT>
Philip Colmer, Mark VandeWettering, Jack Ritter
</H4>
Philip Colmer (<A HREF="mailto:pcolmer@acorn.co.uk">pcolmer@acorn.co.uk</A>) writes:
<P>
As someone who has used QRT and MTV, and is about to try RayShade, could I
make a couple of suggestions to the authors of these packages, and any other
budding ray tracer programmers.
<P>
_________
<P>
Mark VandeWettering (<A HREF="mailto:markv@gauss.Princeton.EDU">markv@gauss.Princeton.EDU</A>) answers Philip's points:
<P>
In article <...> <A HREF="mailto:pcolmer@acorn.co.uk">pcolmer@acorn.co.uk</A> (Philip Colmer) writes:
<P>
&gt;1. Please try and provide an option to produce a quick and dirty outline<BR>
&gt;   image. This would not do any reflections, shadows or any of the other<BR>
&gt;   time consuming elements of ray tracing. Instead, it would just show<BR>
&gt;   where the objects are. This would allow the basic picture to be checked<BR>
&gt;   for accuracy. Not everyone can cope with visualizing a 3D world!<BR>
<P>
<PRE>
        Yeah, this should be configurable from within the data file,
        or via command line options.  Things like raydepth and stuff are
        not run-time configurable on MTV.
</PRE>
<P>
&gt;2. MTV has a very nice colour database (pinched from X11). How about a<BR>
&gt;   similar database for materials, ie just what ARE the parameters that<BR>
&gt;   should be given for metal, glass and so on?<BR>
<P>
<PRE>
        Well, colors are a little easier than things like metals.  We should
        actually shift from an RGB representation of color to a more
        realistic wavelength model, and then convert.  Somewhere I have a list
        compiled by Andrew Glassner of reflection curves for a number of
        materials.   Perhaps these will work their way into Son of MTV.
</PRE>
<P>
&gt;3. How about a fixed point integer system? This would make ray tracers go<BR>
&gt;   one hell of a lot faster, but I'm not sure if this is a viable option.<BR>
<P>
<PRE>
        Guess what folks, this probably won't help.  Mainly because modern
        machines are spending alot more time to do fp multiplies than integer
        multiplies.  Note that on a machine like the i860, a double precision
        multiply can be done every two cycles.  A 32 bit integer multiply
        takes between four and eleven.  Net result: You lose.
        Similar things happen with the MIPS R3000.

        Another big lose for most machines, using single precision fp in
        C.  Doesn't help one iota in speed for every machine I tested, and
        hurt the accuracy.
</PRE>
<P>
________
<P>
Jack Ritter (<A HREF="mailto:ritter@versatc.versatec.COM">ritter@versatc.versatec.COM</A>)<BR>
Organization: Versatec, Santa Clara, Ca. 95051
Summary: speed up tricks for approx ray tracer
<P>
In article (<A HREF="mailto:2413@acorn.co.uk">2413@acorn.co.uk</A>) pcolmer@acorn.co.uk (Philip Colmer) writes:
<P>
&gt;1. Please try and provide an option to produce a quick and dirty outline<BR>
&gt;   image.<BR>
<P>
I have an option to scale the scene into an arbitrary NXM pixel area.  For
initial renderings, where I just want to the overall effect, & make sure
objects don't penetrate each  other, I have found that even a 30X30 pixel
rendering is revealing.  30X30 sure beats the hell out of 512X512, or whatever
these darn kids are using these days.
<P>
I also bound objects in screen space, which makes things very fast when you're
not doing reflections & refractions.  Some fairly complex scenes have taken
under a minute with all these trick in use.  Screen space bounding is
described in the upcoming book "Graphics Gems", which will no doubt also
contain many other speed-up tricks that I will wish I had thought of.
<P>
&gt;3. How about a fixed point integer system? This would make ray tracers go<BR>
&gt;   one hell of a lot faster, but I'm not sure if this is a viable option.<BR>
&gt;<BR>
&gt;       Guess what folks, this probably won't help.  Mainly because modern<BR>
&gt;       machines are spending alot more time to do fp multiplies than integer<BR>
<P>
Yes, the latest processors have on-chip floating point, and are fast.
However, on the processors I have used:  Motorola 68000, 68010, 68020, I have
found that well thought-out fixed point code always beats the floating point
coprocessor, algorithm for algorithm.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art24">
Raytracer Glass,
</A></FONT>
F. Ken Musgrave (<A HREF="mailto:musgrave-forest@CS.YALE.EDU">musgrave-forest@CS.YALE.EDU</A>)
</H4>
Organization: Yale University Computer Science Dept, New Haven CT 06520-2158
<P>
In article <...> <A HREF="mailto:pwh@bradley.UUCP">pwh@bradley.UUCP</A> writes:<BR>
&gt;<BR>
&gt;What are the spectral properties of glass<BR>
&gt;that I could use in a raytracing program?<BR>
&gt;<BR>
&gt;I've a friend who's been working on the problem<BR>
&gt;for a while now, and it's given some interesting results,<BR>
&gt;but nothing that actually looks like glass....<BR>
<P>
<PRE>
  Glass is not so easy to do - I got a Master's degree for doing it!
</PRE>
<P>
  Three things are necessary:  (1) The proper index of refraction (1.5-1.9).
(2) The proper reflection function - Fresnel's Law.  (3) Dispersion.  Also,
you should propagate rays spawned by total internal reflection - many ray
tracers quash such rays outright; this can lead to ugly artifacts in (glass)
objects with planar surfaces.
<P>
  The first two things can be standard features in a ray tracer, the third is
uncommon.  There are two published solutions (that I know of):
<P>
<PRE>
        Thomas, S. W., "Dispersive Refraction in Ray Tracing", Visual
        Computer, vol. 2, no. 1, pp 3-8, Springer Int'l, Jan. '86

        Musgrave, F. K., "Prisms and Rainbows: a Dispersion Model for
        Computer Graphics", Proceedings of the Graphics Interface '89,
        London, Canada, June '89
</PRE>
<P>
  Neither of these references is easy to get.  Perhaps UC Santa Cruz would
provide a copy of my thesis:
<P>
<PRE>
        Musgrave, F. K., "A Realistic Model of Refraction for Computer
        Graphics", Master's Thesis, UC Santa Cruz, Santa Cruz CA, Sept. '87
</PRE>
<P>
  As an alternative, I will put the troff sources for my GI paper where you
can get them via anonymous ftp on <A HREF="ftp://weedeater.math.yale.edu">weedeater.math.yale.edu</A> - but you won't get
any of the nice illustrations.
<P>
  At any rate to get dispersion into a ray tracer requires some hacking, and
will in general slow down the rendering a *lot*.  Thomas & I used quite
different approaches; his would probably be faster for scenes without much
dispersion, and vice-versa.
<P>
  A future version of Craig Kolb's RayShade may feature dispersion...  (I'm
not at liberty to distribute my ray tracer with dispersion.)
<P>
________
<P>
Michael A. Kelly (<A HREF="mailto:mkelly@comix.cs.uoregon.edu">mkelly@comix.cs.uoregon.edu</A>) replies:
[Organization: Department of Computer Science, University of Oregon]
<P>
In article (<A HREF="mailto:8600001@bradley">8600001@bradley</A>) pwh@bradley.UUCP writes:<BR>
&gt;<BR>
&gt;What are the spectral properties of glass<BR>
&gt;that I could use in a raytracing program?<BR>
<P>
Try "Color Science" by Wyszecki & Stiles (1982).  I don't have the book with
me but I'm pretty sure it has the information you need.
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art25">
Ray Intersection with Grid,
</A></FONT>
Rick Speer (<A HREF="mailto:speer@boulder.Colorado.EDU">speer@boulder.Colorado.EDU</A>)
</H4>
Organization: University of Colorado, Boulder
<P>
In article 12598 of comp.graphics, aiadrmi@castle.ed.ac.uk
(Alasdair Donald Robert McIntyre) writes:
<P>
&gt;  I am trying to raytrace rippling water and need to solve the following<BR>
&gt;  problem:<BR>
&gt;<BR>
&gt;           Given a surface defined by heights on an square grid, find the<BR>
&gt;           closest intersection of a ray with the surface thus defined.<BR>
&gt;<BR>
&gt;  I wonder if anyone knows of an efficient method to do this?<BR>
&gt;<BR>
&gt;  Replies by mail, or to the net.<BR>
&gt;  Thanks in advance<BR>
<P>
You might check the following-
<P>
1. "Shaded Display of Digital Maps", by S. Coquillart and M. Gangnet
    in IEEE Computer Graphics and Applications V. 4 No. 7 (July 1984),
    p. 35-42.
<P>
2. "Vectorized Procedural Models for Natural Terrain: Waves and
    Islands in the Sunset", by N. Max in Computer Graphics V. 15 No. 3
    (Proceedings of SIGGRAPH '81), p. 317-324.
<P>
These should give you some good ideas.
<P>
[My own two cents:  Also look at "The Synthesis and Rendering of Eroded Fractal
Terrains" by F. Kenton Musgrave, Craig E. Kolb, and Robert S. Mace, SIGGRAPH
89.  Towards the end they describe their method to ray trace height fields.
- EAH]
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<H4><FONT size=+1><A NAME="art26">
Database for DBW-Render,
</A></FONT>
by Prem Subrahmanyam (<A HREF="mailto:prem@geomag.fsu.edu">prem@geomag.fsu.edu</A>)
</H4>
Organization: Florida State University Computing Center
<P>
Ok, here is a description file for a trio of balloons over reflective water
with fractal mountains in the background.  It should be pretty interesting.
<P>
<PRE>
& 0 400
R 24.0
a .5
b .8 .4 .4
e 0 10 100  0 -5 -200  0 1 0
w  0 0 -200  7 .1 1 0.00
w 0 0 0  5 .2 1 0.00
w 0 0 200  20 .4 1 0.50
w 200 0 0  2  .1  1  1.00
w -200 0 0  10 .15  1 1.00
w 50 0 0  6 .2 1 0.00
w 30 4 60  15 .3 1 .75
l  1 1 1  2 10 5
g .5 0 .8  15 15
f 4  0.1 0.5 0.7  3
f 4  .7 .6 .6  3
f 4  .5 .5 .7  3
{s 50 .2 0 1  0 0 0  .3 .3 .3  .6 .8 .2  0 29 0  10
{t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  -9 24.2 0  1.7 0 5.3  5.3 -10.2 1.2
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  -7.3 24.2 5.3  4.5 0 3.3  5 -10.2
-2
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  -2.8 24.2 8.6  5.6 0 0  2.8 -10.2
-4.7
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  2.8 24.2 8.6  4.5 0 -3.3  -.5 -10.2
-5.4
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  7.3 24.2 5.3  1.7 0 -5.3  -3.6
-10.2 -4.1
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  -2.3 14 3.2 -1.4 0 -2
-5 10.2 2
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  0 14 3.9 -2.3 0 -.7  -2.8 10.2 4.7
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  2.3 14 3.2  -2.3 0 .7  .5 10.2 5.4
 t 50 .2 0 1  0 0 0  .1 .1 .1  .6 .87 .2  3.7 14 1.2 -1.4 0 2  3.6 10.2
4.1}
{q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  0 14 3.9  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  3.7 14 1.2  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  -3.7 14 1.2  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  -.8 14 -3.9  .4 0 0  0 -8 0}
{q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  -3.7 6 1.2  3.7 0 2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  0 6 3.9  3.7 0 -2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  -3.7 6 1.2  2.9 0 -2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  -.8 6 -3.9  4.5 0 2.7  0 -5 0}}


 r 4 0 .55 1  0 0 0  0 0 0  .1 0 0   0 1 0   1 0 0  0 0 1  0  200

{s 70 .2 0 1  0 0 0  .3 .3 .3  .5 0 .2  20 30 -10  10
{t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  11 25.2 -10  1.7 0 5.3  5.3 -10.2 1.2
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  12.7 25.2 -4.7  4.5 0 3.3  5 -10.2
-2
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  17.2 25.2 -1.4  5.6 0 0  2.8 -10.2
-4.7
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  22.8 25.2 -1.4  4.5 0 -3.3  -.5 -10.2
-5.4
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  27.3 25.2 -4.7  1.7 0 -5.3  -3.6
-10.2 -4.1
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  17.7 15 -6.8 -1.4 0 -2
-5 10.2 2
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  20 15 -6.1 -2.3 0 -.7  -2.8 10.2 4.7
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  22.3 15 -6.8  -2.3 0 .7  .5 10.2 5.4
 t 70 .2 0 1  0 0 0  .1 .1 .1  .5 0 .2  23.7 15 -8.8 -1.4 0 2  3.6 10.2
4.1}
{q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  20 15 -6.1  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  23.6 15 -8.8  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  16.3 15 -8.8  .45 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  19.2 15 -13.9  .4 0 0  0 -8 0}
{q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  16.3 7 -11.2  3.7 0 2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  20 7 -6.1  3.7 0 -2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  16.3 7 -8.8  2.9 0 -2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  19.2 7 -13.9  4.5 0 2.7  0 -5 0}}

{s 5 .2 0 1  0 0 0  .3 .3 .3   0 .5 .8  -30 40 -20  10
{t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -39 35.2 -20  1.7 0 5.3  5.3 -10.2 1.2
 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -37.3 35.2 -14.7  4.5 0 3.3  5 -10.2
-2
 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -32.8 35.2 -11.4  5.6 0 0  2.8 -10.2
-4.7
 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -27.2 35.2 -11.4  4.5 0 -3.3  -.5 -10.2
-5.4
 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -22.7 35.2 -14.7  1.7 0 -5.3  -3.6
-10.2 -4.1
 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -32.2 25 -16.2 -1.4 0 -2
-5 10.2 2
 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -30 25 -16.1 -2.3 0 -.7  -2.8 10.2 4.7

 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -27.7 25 -16.8  -2.3 0 .7  .5 10.2 5.4
 t 5 .2 0 1  0 0 0  .1 .1 .1   0 .5 .8  -26.3 25 -18.8 -1.4 0 2  3.6 10.2
4.1}
{q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  -30 25 -16.1  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  -26.4 25 -18.8  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  -33.7 25 -18.8  .4 0 0  0 -8 0
 q 0 1 0 1  0 0 0  .1 .1 .1   .1 .1 .1  -30.8 25 -23.9  .4 0 0  0 -8 0}
{q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  -33.7 17 -18.8  3.7 0 2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  -30 17 -16.1  3.7 0 -2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  -33.7 17 -18.8  2.9 0 -2.7  0 -5 0
 q 3 .5 0 1  0 0 0  .1 .1 .1  .3 .4 .5  -30.8 17 -23.9  4.5 0 2.7  0 -5 0}}
 x 60 0 0 1  0 0 0  .1 .1 .1  .4 .4 .4  -100 0 -170  0 30 -200  100 0 -170
 x 61 0 0 1  0 0 0  .1 .1 .1  .4 .4 .4  -50 0 -170  -150 50 -132  -180 0 -85
 x 62 0 0 1  0 0 0  .1 .1 .1  .4 .4 .4  50 0 -170  160 30 -132  180 0 -85
 k .8 0 .9  5 5 5  0 0 0
</PRE>
<P>
<IMG src="teadot.gif">
back to
<A HREF="#contents">contents</A>
<HR>
<ADDRESS>
Eric Haines / <A HREF="mailto:erich@acm.org">erich@acm.org</A>
</ADDRESS>
</BODY>
</HTML>
